{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🧑‍🏫 Task 1 Part 2: Build Your Own Logistic Regression Model for Sentiment Analysis\n",
    "In this exercise, you will build a **logistic regression model** from scratch to perform sentiment analysis.\n",
    "\n",
    "**Objective:** Implement all key components of an ML pipeline (except for data handling).\n",
    "\n",
    "**Allowed Libraries:** `pandas`, `numpy`\n",
    "\n",
    "**Not Allowed:** Any pre-built ML algorithms or functions like `LogisticRegression` from `sklearn`.\n",
    "\n",
    "Follow the instructions step-by-step and answer the questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the Data\n",
    "**Task:** Use `pandas` to load the dataset from a file named `IMDB_reviews.csv`.\n",
    "\n",
    "> **Hint:** Use `pd.read_csv()` to load the file and display the first 5 rows.\n",
    "\n",
    "**Question:** What are the key features and the target variable in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['review', 'sentiment']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset and display the first few rows\n",
    "import pandas as pd\n",
    "f=pd.read_csv('IMDB_Dataset.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Tokenization and Text Cleaning\n",
    "**Task:** Implement your own function to:\n",
    "1. Convert all text to lowercase.\n",
    "2. Remove punctuation and special characters.\n",
    "3. Split the text into words (tokenization).\n",
    "\n",
    "> **Hint:** Use Python string methods and list comprehensions.\n",
    "\n",
    "**Question:** Why is tokenization important for text-based models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'other',\n",
       " 'reviewers',\n",
       " 'has',\n",
       " 'mentioned',\n",
       " 'that',\n",
       " 'after',\n",
       " 'watching',\n",
       " 'just',\n",
       " '1',\n",
       " 'oz',\n",
       " 'episode',\n",
       " \"you'll\",\n",
       " 'be',\n",
       " 'hooked.',\n",
       " 'they',\n",
       " 'are',\n",
       " 'right,',\n",
       " 'as',\n",
       " 'this',\n",
       " 'is',\n",
       " 'exactly',\n",
       " 'what',\n",
       " 'happened',\n",
       " 'with',\n",
       " 'me.<br',\n",
       " '/><br',\n",
       " '/>the',\n",
       " 'first',\n",
       " 'thing',\n",
       " 'that',\n",
       " 'struck',\n",
       " 'me',\n",
       " 'about',\n",
       " 'oz',\n",
       " 'was',\n",
       " 'its',\n",
       " 'brutality',\n",
       " 'and',\n",
       " 'unflinching',\n",
       " 'scenes',\n",
       " 'of',\n",
       " 'violence,',\n",
       " 'which',\n",
       " 'set',\n",
       " 'in',\n",
       " 'right',\n",
       " 'from',\n",
       " 'the',\n",
       " 'word',\n",
       " 'go.',\n",
       " 'trust',\n",
       " 'me,',\n",
       " 'this',\n",
       " 'is',\n",
       " 'not',\n",
       " 'a',\n",
       " 'show',\n",
       " 'for',\n",
       " 'the',\n",
       " 'faint',\n",
       " 'hearted',\n",
       " 'or',\n",
       " 'timid.',\n",
       " 'this',\n",
       " 'show',\n",
       " 'pulls',\n",
       " 'no',\n",
       " 'punches',\n",
       " 'with',\n",
       " 'regards',\n",
       " 'to',\n",
       " 'drugs,',\n",
       " 'sex',\n",
       " 'or',\n",
       " 'violence.',\n",
       " 'its',\n",
       " 'is',\n",
       " 'hardcore,',\n",
       " 'in',\n",
       " 'the',\n",
       " 'classic',\n",
       " 'use',\n",
       " 'of',\n",
       " 'the',\n",
       " 'word.<br',\n",
       " '/><br',\n",
       " '/>it',\n",
       " 'is',\n",
       " 'called',\n",
       " 'oz',\n",
       " 'as',\n",
       " 'that',\n",
       " 'is',\n",
       " 'the',\n",
       " 'nickname',\n",
       " 'given',\n",
       " 'to',\n",
       " 'the',\n",
       " 'oswald',\n",
       " 'maximum',\n",
       " 'security',\n",
       " 'state',\n",
       " 'penitentary.',\n",
       " 'it',\n",
       " 'focuses',\n",
       " 'mainly',\n",
       " 'on',\n",
       " 'emerald',\n",
       " 'city,',\n",
       " 'an',\n",
       " 'experimental',\n",
       " 'section',\n",
       " 'of',\n",
       " 'the',\n",
       " 'prison',\n",
       " 'where',\n",
       " 'all',\n",
       " 'the',\n",
       " 'cells',\n",
       " 'have',\n",
       " 'glass',\n",
       " 'fronts',\n",
       " 'and',\n",
       " 'face',\n",
       " 'inwards,',\n",
       " 'so',\n",
       " 'privacy',\n",
       " 'is',\n",
       " 'not',\n",
       " 'high',\n",
       " 'on',\n",
       " 'the',\n",
       " 'agenda.',\n",
       " 'em',\n",
       " 'city',\n",
       " 'is',\n",
       " 'home',\n",
       " 'to',\n",
       " 'many..aryans,',\n",
       " 'muslims,',\n",
       " 'gangstas,',\n",
       " 'latinos,',\n",
       " 'christians,',\n",
       " 'italians,',\n",
       " 'irish',\n",
       " 'and',\n",
       " 'more....so',\n",
       " 'scuffles,',\n",
       " 'death',\n",
       " 'stares,',\n",
       " 'dodgy',\n",
       " 'dealings',\n",
       " 'and',\n",
       " 'shady',\n",
       " 'agreements',\n",
       " 'are',\n",
       " 'never',\n",
       " 'far',\n",
       " 'away.<br',\n",
       " '/><br',\n",
       " '/>i',\n",
       " 'would',\n",
       " 'say',\n",
       " 'the',\n",
       " 'main',\n",
       " 'appeal',\n",
       " 'of',\n",
       " 'the',\n",
       " 'show',\n",
       " 'is',\n",
       " 'due',\n",
       " 'to',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'it',\n",
       " 'goes',\n",
       " 'where',\n",
       " 'other',\n",
       " 'shows',\n",
       " \"wouldn't\",\n",
       " 'dare.',\n",
       " 'forget',\n",
       " 'pretty',\n",
       " 'pictures',\n",
       " 'painted',\n",
       " 'for',\n",
       " 'mainstream',\n",
       " 'audiences,',\n",
       " 'forget',\n",
       " 'charm,',\n",
       " 'forget',\n",
       " 'romance...oz',\n",
       " \"doesn't\",\n",
       " 'mess',\n",
       " 'around.',\n",
       " 'the',\n",
       " 'first',\n",
       " 'episode',\n",
       " 'i',\n",
       " 'ever',\n",
       " 'saw',\n",
       " 'struck',\n",
       " 'me',\n",
       " 'as',\n",
       " 'so',\n",
       " 'nasty',\n",
       " 'it',\n",
       " 'was',\n",
       " 'surreal,',\n",
       " 'i',\n",
       " \"couldn't\",\n",
       " 'say',\n",
       " 'i',\n",
       " 'was',\n",
       " 'ready',\n",
       " 'for',\n",
       " 'it,',\n",
       " 'but',\n",
       " 'as',\n",
       " 'i',\n",
       " 'watched',\n",
       " 'more,',\n",
       " 'i',\n",
       " 'developed',\n",
       " 'a',\n",
       " 'taste',\n",
       " 'for',\n",
       " 'oz,',\n",
       " 'and',\n",
       " 'got',\n",
       " 'accustomed',\n",
       " 'to',\n",
       " 'the',\n",
       " 'high',\n",
       " 'levels',\n",
       " 'of',\n",
       " 'graphic',\n",
       " 'violence.',\n",
       " 'not',\n",
       " 'just',\n",
       " 'violence,',\n",
       " 'but',\n",
       " 'injustice',\n",
       " '(crooked',\n",
       " 'guards',\n",
       " \"who'll\",\n",
       " 'be',\n",
       " 'sold',\n",
       " 'out',\n",
       " 'for',\n",
       " 'a',\n",
       " 'nickel,',\n",
       " 'inmates',\n",
       " \"who'll\",\n",
       " 'kill',\n",
       " 'on',\n",
       " 'order',\n",
       " 'and',\n",
       " 'get',\n",
       " 'away',\n",
       " 'with',\n",
       " 'it,',\n",
       " 'well',\n",
       " 'mannered,',\n",
       " 'middle',\n",
       " 'class',\n",
       " 'inmates',\n",
       " 'being',\n",
       " 'turned',\n",
       " 'into',\n",
       " 'prison',\n",
       " 'bitches',\n",
       " 'due',\n",
       " 'to',\n",
       " 'their',\n",
       " 'lack',\n",
       " 'of',\n",
       " 'street',\n",
       " 'skills',\n",
       " 'or',\n",
       " 'prison',\n",
       " 'experience)',\n",
       " 'watching',\n",
       " 'oz,',\n",
       " 'you',\n",
       " 'may',\n",
       " 'become',\n",
       " 'comfortable',\n",
       " 'with',\n",
       " 'what',\n",
       " 'is',\n",
       " 'uncomfortable',\n",
       " 'viewing....thats',\n",
       " 'if',\n",
       " 'you',\n",
       " 'can',\n",
       " 'get',\n",
       " 'in',\n",
       " 'touch',\n",
       " 'with',\n",
       " 'your',\n",
       " 'darker',\n",
       " 'side.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write your own tokenizer function\n",
    "def process(text):\n",
    "    text=text.lower()\n",
    "    return list(text.split())\n",
    "process(f['review'][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create a Vocabulary\n",
    "**Task:** Create a **vocabulary** (a list of unique words) from the tokenized dataset.\n",
    "\n",
    "> **Hint:** Use a set to store unique words, then convert it to a list.\n",
    "\n",
    "**Question:** How does vocabulary size affect model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Implement Word Count\n",
    "**Task:** Calculate and store the number of times each word appears in a particular review for all reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Example: Write functions to calculate word counts\n",
    "def wordcount(text):\n",
    "    ans={}\n",
    "    for i in text:\n",
    "        if i in ans:\n",
    "            ans[i]+=1\n",
    "        else:\n",
    "            ans[i]=1\n",
    "    return ans\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Train-Test Split\n",
    "**Task:** Split the data into **80% training** and **20% testing** sets.\n",
    "\n",
    "> **Hint:** Use `numpy` or list slicing to split the data manually.\n",
    "\n",
    "**Question:** Why do we need to split the data for training and testing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Building the Logistic Regression Model (Divided Steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: The Prediction functions\n",
    "The **prediction function** returns the predicted value of the data point using the weights and the bias. It uses the sigmoid function to convert the prediction into a value in the range of 0 to 1.\n",
    "\n",
    "**Task:** Implement the sigmoid and prediction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def sigmoid(x):\n",
    "    return 1/(1-math.pow(math.e,x))\n",
    "\n",
    "import numpy as np\n",
    "def lr_prediction(weights,\tbias,\tfeatures):\n",
    "    a=np.dot(weights,features)+bias\n",
    "    return sigmoid(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Implementing the Error functions\n",
    "**Task:** Use the gradient update rules to train the logistic regression model over multiple epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def\tlog_loss(weights,\tbias,\tfeatures,\tlabel):\n",
    "    func=lr_prediction(weights,\tbias,\tfeatures)\n",
    "    cost=  -label*np.log(func) - (1-label)*np.log(1-func)\n",
    "    return cost\n",
    "\n",
    "def\ttotal_log_loss(weights,\tbias,\tX,\ty):\n",
    "    total=0\n",
    "    m=X.shape[0]\n",
    "    for i in range(m):\n",
    "        total+=log_loss(weights,\tbias,\tX[i],\ty[i])\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Update Weights\n",
    "The **Update_Weights** adjusts weights and bias based on whether points are correctly or incorrectly classified, It is a simple method of improving the model at every iteration:\n",
    "1. **Correctly classified points:** Move the line **away** from the point.\n",
    "2. **Incorrectly classified points:** Move the line **towards** the point.\n",
    "\n",
    "**Task:** Implement the gradient update function based on these rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your Code\n",
    "def\tlr_update_weights(weights,\tbias,\tfeatures,\tlabel,\tlearning_rate\t=\t0.01):\n",
    "    \n",
    "    return  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Implementing the Logistic Regression Algorithm\n",
    "**Task:** Use the function to update weights to train the logistic regression model over multiple epochs. Keep track of the total error for each epoch. You will later plot these errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the logistic regression model \n",
    "def\tlr_algorithm(features,\tlabels,\tlearning_rate\t=\t0.01,\tepochs\t=\t200):\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Evaluate Your Model\n",
    "**Task:** Calculate the accuracy of the model. Compare the predicted labels with the actual labels.\n",
    "\n",
    "> **Hint:** Use the formula for accuracy: (Correct Predictions / Total Predictions) * 100\n",
    "\n",
    "**Question:** Which metric—accuracy, precision, or recall—is most important for sentiment analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Visualize the Errors  \n",
    "**Task:** Create a scatter plot of the total errors over the training epochs. The plot should show a gradual decrease in errors, stabilizing as the model converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Make Predictions on New Data\n",
    "**Task:** Use your trained model to predict the sentiment of the following review:\n",
    "\n",
    "> _\"The movie was absolutely fantastic and kept me hooked till the end.\"_\n",
    "\n",
    "**Question:** What challenges might arise when predicting on new data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Wrap-up\n",
    "1. How well did your model perform?\n",
    "2. What challenges did you face while implementing it from scratch?\n",
    "3. What improvements would you suggest for the future?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes (if any):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
